\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{color}

\setlength{\topmargin}{0.1in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textheight}{9in}
\setlength{\textwidth}{6.5in}

\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}

\newcommand{\question}[1]{\bgroup\color{blue}#1\egroup}

\title{CS515 HW1}
\author{Steve Hill, Erich Merrill, Kenneth Shultz}
\date{October 2015}

\begin{document}

\maketitle

\begin{enumerate}
\item 
    \begin{enumerate}
    \item 
      \question{Prove that the following algorithm actually sorts its input.}
    %Solution goes here%

  \begin{itemize}
  \item Base case, $n=0,1$

  Any list of length 0 or 1 is necessarily sorted. Therefore stoogesort can sort any list of length 0 or 1.

  \item Base case, $n=2$

  A list of length 2 is sorted if and only if its second element is smaller than its first element. 
  When stoogesort is given a list of length 2, it swaps the positions of the two list elements if the second element is smaller than the first element. If the second element is larger than the first (i.e. the list is already sorted), stoogesort does nothing.
  Therefore stoogesort can correctly sort any list of length 2.

  \item Inductive step, $n>2$

  For any list of size $n > 2$, stoogesort first sorts the first $m=\ceil{\frac{2n}{3}}$ elements of the list (via the inductive hypothesis), then sorts the last $m$ elements of the list, and finally sorts the first $m$ elements of the list again.
  
  For stoogesort to be able to correctly sort any list, the overlap between the first `sub-region' to be sorted and the second one must be at least as large as the size of the portion of the array not included each intermediate sorting step.
  Otherwise, it would be possible for elements that start on the opposite side of the list from where they belong to get `stuck' in the wrong two-thirds of the list, unable to propigate through to its correct final location.

  We know that the amount of the array not included in each sub-sorting step is $\floor{\frac{n}{3}}$, since $\ceil{\frac{2n}{3}} + \floor{\frac{n}{3}} = n$. We can also calculate the size of the overlap by subtracting the relevant indices each sorting sub-step uses.

  \begin{align*}
    \ceil{\frac{2n}{3}} - 1 - n + \ceil{\frac{2n}{3}} + 1 &\geq \floor{\frac{n}{3}}\\
    2\ceil{\frac{2n}{3}} - n &\geq \floor{\frac{n}{3}}\\
    2\ceil{\frac{2n}{3}} - \floor{\frac{n}{3}} &\geq n\\
  \end{align*}

  Intuitively this inequality should hold. If we assume the floor and ceiling can be `cancelled out', we can remove them to get:

  \begin{align*}
    \frac{4n}{3} - \frac{n}{3} &\geq n\\
    \frac{3n}{3} \geq n\\
  \end{align*}

  Which is obviously correct. However, we're unsure how to reason about floor/ceilings in such a way to prove this rigorously.

  \end{itemize}

    \item
      \question{Would StoogeSort still sort correctly if we replaced $m = \ceil{2n/3}$ with $m = \floor{2n/3}$? Justify
      your answer.}
    %Solution goes here%

No. Consider a list of length 4. In this case, $m$ would be set to $m = \floor{\frac{2 \times 4}{3}} = 2$. 
The first sorting step of stoogesort will sort elements $0$ through $1$, and the second step will sort elements $2$ through $3$.
Since the two sorting steps clearly don't overlap, it would be impossible for any element at the beginning of the list to propigate up to the end of the list.

Therefore, stoogesort would be unable to correctly sort lists if the ceiling was replaced by a floor.

 
    \item
      \question{State a recurrence (including the base case(s)) for the number of comparisons executed by
      StoogeSort.}

Stoogesort only compares two list elements when the size of the list it's given to sort is 2. Otherwise, it calls stoogesort three times on lists of size $\ceil{\frac{2n}{3}}$. Therefore, we can state the recurrence relation of the number of list element comparisons as:

\begin{align*}
T(1) &= 0\\
T(2) &= 1\\
T(n) &= 3T(\ceil{\frac{2n}{3}})
\end{align*}

    \item 
      \question{Solve the recurrence, and prove that your solution is correct. }

    Any $T(n)$ can be expanded to: (if we ignore the ceiling)
    \begin{align*}
      T(n) &= 3^k T\left(\left(\frac{2}{3}\right)^k n\right)\\
    \end{align*}

    If we set $k$ to some value such that $\left(\frac{2}{3}\right)^k n = 2$, then the expanded representation becomes:

    \begin{align*}
      T(n) &= 3^k T\left(\left(\frac{2}{3}\right)^k n\right)\\
      &= 3^k T(2)\\
      T(n) &= 3^k\\
    \end{align*}

    So if we solve for $k$:
    
    \begin{align*}
      n \left(\frac{2}{3}\right)^k &= 2\\
      \frac{2}{n} &= \left(\frac{2}{3}\right)^k\\
      \log_2\left(\frac{2}{n}\right) &= k \log_2\left(\frac{2}{3}\right)\\
      \log_2(2) - \log_2(n) &= k\left(\log_2(2) - \log_2(3)\right)\\
      1 - \log_2(n) &= k\left(1 - log_2(3)\right)\\
      k &= \frac{1 - \log_2(n)}{1 - \log_2{3}}
    \end{align*}

    We can say that for any $n > 2$,

    \begin{align*}
      T(n) = 3^{\frac{1 - \log_2(n)}{1 - \log_2{3}}}\\
    \end{align*}

    \item
      \question{Prove that the number of swaps executed by StoogeSort is at most $n \choose 2$}

      The only way that stoogesort moves elements through the array during sorting is by swapping any given element with its neighbor, when appropriate.

      Consider an array that is sorted in reverse (i.e. the largest element is at index 0, the second largest element is at index 1, etc). Since we know that stoogesort can correctly sort the array, the largest element must 


    \end{enumerate}

\item 
  \question{An inversion in an array A[1..n] is a pair of indices $(i, j)$ such that $i < j$ and
$A[i] > A[j]$. The number of inversions in an n-element array is between 0 (if the array is sorted)
and $n \choose 2$ (if the array is sorted backward). Describe an algorithm to count the number of inversions
in an n-element array in $O(n log n)$ time. Prove your algorithm is correct and analyze its running
time
}

%Solution goes here%

We can modify the mergesort algorithm to an algorithm `inversion-mergesort' which also returns the number of inversions in an array as it sorts the array.

Similar to mergesort, the algorithm would first divide the array into two parts. 
The number of inversions in the array would then be equal to the number of inversions in the first half of the array (which is calculated by calling `inversion-mergesort' on the sub-array), plus the number of inversions in the second half of the array, plus the number of inversions detected while merging the two (sorted) sub-arrays using an `inversion-merge' function which merges the sub-arrays while counting the number of inversions.

Pseudo-code for the algorithm has been omitted for brevity, but `inversion-merge' is similar to the standard `merge' algorithm, except it keeps a running count of the number of inversions which is initialized to zero. 
Additionally, when `inversion-merge' finds an element in the first array at index $i$ that is greater than an element in the second array at index $j$ (i.e. $A[i] > B[j]$), it adds $m-i$ to the number of inversions, where $m$ is the length of the first array.

Since both sub-arrays are sorted as a precondition to calling `inversion-merge', if $B[j] < A[i]$ it follows that $B[j] < A[k]$ for all $i <= k <=m$. Therefore, since we know that $A[i..m] > B[j]$ and that all elements in $B$ come `after' the elements in $A$, there must be $m-i$ inversions.

In all the other `merge' cases, there are demonstrably no inversions. If either array has been exhausted, then the elements are being inserted in-place into the final array and therefore must not be inversions. In the case that $A[i] < B[j]$ there are also no inversions, since every $A$ comes before any element in $B$, and the first element is smaller.

\item 
  \question{
A shuffle of two strings X and Y is formed by interspersing the characters into a new string,
keeping the characters of X and Y in the same order. For example, the string BANANAANANAS
is a shuffle of the strings BANANA and ANANAS in several different ways.
Similarly, the strings PRODGYRNAMAMMIINCG and DYPRONGARMAMMICING are both
shuffles of DYNAMIC and PROGRAMMING.
}

Given three strings $A[1..m], B[1..n]$, and $C[1..m + n]$, describe an algorithm to determine
whether C is a shuffle of X and Y. Prove your algorithm is correct and analyze its running time.
%Solution goes here%

$$
\text{isShuffle}(C, X, Y) 
    \begin{cases}
    
      True & \text{if } \text{RecursiveHelper}(C,X,Y) = \text{length}(C) \\
    False, & \text{otherwise}
    \end{cases}
$$


Consider the following recurrence relation:


$\text{RecursiveHelper}(C, X, Y)$:\\
$$
    max  
    \begin{cases}
      \text{RecursiveHelper}(C[1:], X[1:], Y) + 1   & \text{if } C[0] = X[0])\\
      \text{RecursiveHelper}(C[1:], X, Y[1:]) + 1    & \text{if } C[0] = Y[0]\\
      1  & \text{if } C(i) = X(i) \text{ and } \text{length}(Y) = 0\\
      1  & \text{if } C(i) = Y(i) \text{ and } \text{length}(X) = 0\\
        0 & \text{otherwise}
    \end{cases}
$$
The base case is defined as if C only contains one element and there is a match, return 1. If there is no match, return 0. This allows isShuffle to evaluate the length at the end of the recurrence as a measure of if C is a shuffle of X and Y.
The recurrence is looking for a match from either the first position in X or Y to C, if there is a match, it removes the beginning of C and the corresponding character in X or Y and recurses. \\

Proof of correctness:\\
\\
\emph{Theorem:} The above recurrence relation solves the shuffled string problem. \\
\emph{Proof:} \\
Let C be length 1, X be length 0, and Y be length 0. RecursiveHelper would return 0 by the last case and is Shuffle would return false. \\
Let C be Length 1, X be length 1, and Y be length 0. If X is the same character as C, it will return 1, which is the length of the string, thus isShuffle returns true and the algorithm is correct. Similariy, if they are not equal, then the algorithm will reach the last case and return false\\
Let k be the length of C. Let i,j be the length of X, Y respectively. \\
Let $k > 1$ and length of X + length of $Y > 1$: \\
\\
For k = 2, it is easy to see that both X and Y must be one character and contained in C in order for isShuffle to return True, if there are two matches, case 3 and case 4 will respectively be met in both paths. Thus the max will be 2 and the algorithm will succeed and correctly return true. If there is no match, both RecursiveHelper calls will return 1 and isShuffle will return true. From here it is easy to see that for k+1, isShuffle will always return the correct answer.
\\
QED\\

\emph{Dynamic Programming}:\\
\\
$\text{isShuffleDP}(C, X, Y)$\\

Construct a $n+1 x m+1$ table denoted T. At position 0x0, place a 0. \\
Move through the table from left to right and suppose i and j represent the current indicies\\
In each cell, enter the following: \\
    \[
     max
    \begin{cases}
        T(i - 1, j) + 1  & \text{if } C[i+j] = X[i])\\
        T(i, j - 1) + 1  & \text{if } C[ni+j] = Y[j])\\
        0, & \text{otherwise}
    \end{cases}
    \]
This will populate every cell with the computations required the isShuffled recurrence relation in $O(|C|^2)$ time using $O(|C|^2)$ space. Either isShuffled may be run using the table as supplementary table, or you may use the cell at position n,m. If it is equal to the length of C, then the string is shuffled, otherwise C is not a shuffle of X and Y.


\item 
  \question{
You are driving a bus along a highway, full of rowdy, hyper, thirsty students
and a soda fountain machine. Each minute that a student is on your bus, that student drinks one
ounce of soda. Your goal is to drop the students off quickly, so that the total amount of soda
consumed by all students is as small as possible.

You know how many students will get off of the bus at each exit. Your bus begins somewhere
along the highway (probably not at either end) and move s at a constant speed of 3.14 miles per
hour. You must drive the bus along the highway; however, you may drive forward to one exit then
backward to an exit in the opposite direction, switching as often as you like. (You can stop the
bus, drop off students, and turn around instantaneously.)

Describe an efficient algorithm to drop the students off so that they drink as little soda as
possible. Your input consists of the bus route (a list of the exits, together with the travel time
between successive exits), the number of students you will drop off at each exit, and the current
location of your bus (which you may assume is an exit). Prove your algorithm is correct and analyze
its running time.
}

You know how many students will get off of the bus at each exit. Your bus begins somewhere along the highway (probably not at either end) and move s at a constant speed of 3.14 miles per hour. You must drive the bus along the highway; however, you may drive forward to one exit then backward to an exit in the opposite direction, switching as often as you like. (You can stop the bus, drop off students, and turn around instantaneously.)\\

Describe an efficient algorithm to drop the students off so that they drink as little soda as possible. Your input consists of the bus route (a list of the exits, together with the travel time between successive exits), the number of students you will drop off at each exit, and the current location of your bus (which you may assume is an exit). Prove your algorithm is correct and analyze its running time.\\
\\
Consider the following recurrence relation:\\

def SodaBus(Exits, position, Children, RemainingLimit=$|Exits| \choose 2$):
    \[
        \begin{cases}
            0 & \text{if } |C| = 0\\
            min
            \begin{cases}
            |C| * d(P, P+1) + SodaBus(E, p+1, C', RemainingLimit - 1) \\
            |C| * d(P, P-1) + SodaBus(E, p-1, C'', RemainingLimit - 1)\\
            \end{cases} & \text{otherwise}
        \end{cases}
    \]
\\
The above algorithm simply returns 0 if the bus is empty, or returns the cheapest route considering the sub-problems. The next "move" you take is the argmin of the sub-problem, however we are still returning the distance in order to properly move through the recursion. The last important thing to note is RemainingLimit -- This sets a maximum number of steps the algorithm can take before returning of $n \choose 2$.\\

$Theorem:$ The above recurrence relation solves the SodaBus problem. \\
The first thing to note is the RemainingLimit parameter. This parameter is equal at the highest level or recursion to $n \choose 2$. This is the longest path a bus may take before reaching every stop at least once. Since students are dropped off upon reaching a stop, this is another way of representing our solution space. There is no purpose to explore solutions outside of this space (it also may cause infinite looping). $n \choose 2$ is chosen because the longest path appears when the bus starts at a central stop. Following the route: 
\[p+1, p-2, p+3, p-4 ... p+n\]
This continues until the bus has reached every node once and is equivalent to $n \choose 2$. \\

We will consider the recurrence relation itself.\\
In the simplest case, that the bus has no children, it is easy to see that it returns 0 and we are done.\\
Suppose there are 2 stops, and there are students who need to be dropped off at your current position. Both sub-problems will return 0 + the cost of doing nothing, which is also 0. It is easy to see this is correct.\\
Assume the students belong to the next stop. The sub-problem which moves to this exit, suppose P+1, will evaluate to just the cost of driving there, as it will resolve the base-case. The alternative will continue to accumulate cost until returning to the current position and evaluating the P+1 case anyway.\\
It follows that for any problem greater than these above three will ultimately resolve to the above three cases, and thus, solved.\\

\emph{Dynamic Programming:}\\

For the dynammic programming implementation of the above algorithm, which runs in $O(2^{n \choose 2})$  time, consider the use of a tree structure, where the root is the starting position, $s$. The children of $s$ and all grandchildren, the left corresponds to positions $p-1$, and the right, $p+1$. Each node contains the cost to travel to it's children. In addition, we also will store a memoization hash table which contains two pieces of information, p, and a boolean array of which exits have been visited.\\
To fill the table, proceed in depth-first manner. If any node (p, exit-array), is in our table, skip it and immediately return to the parent of that node. This allows us to save our work and keep from doubling back at any given time.\\
After the tree is filled, starting from $s$, follow the child node with the smallest cost until you reach a terminal node.\\

You can see this is equivalent to the recurrence relation by noting that each branch represents the two sub-problems in the recurrence relation. By saving each p, exit-array pair we can save a significant amount of time when building the tree.

We do not have a solution for the runtime of the algorithm, however, when examining the runtime on different size solution, it seemed to be of the order $O(|E|^2)$. 

\end{enumerate}

\end{document}


